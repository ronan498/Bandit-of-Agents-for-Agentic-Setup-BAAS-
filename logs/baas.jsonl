{"t": 0, "arm": "basic_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.05162420382165603, "plan": {"framework": "LangChain", "tools": ["python_repl", "search"], "max_steps": 3, "task": "summarize", "task_input": "Reflective agents can retry and self-evaluate; graphs orchestrate multi-step reasoning.", "constraints": {"max_latency_s": 1.6, "max_cost_usd": 0.002, "deny_arms": [], "w_quality": 1.0, "w_cost": 1.0, "w_latency": 0.2}}, "metrics": {"cpu_ms_small": 0.9807099995668977, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 3, "smoke_pass": 1, "framework_langchain": 1, "framework_autogen": 0}, "explanation": "Chose basic_agentic given context; tuned steps to 3. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 1, "arm": "reflective_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.18848837209302327, "plan": {"framework": "AutoGen", "tools": ["python_repl", "search", "retry", "reflect"], "max_steps": 3, "task": "summarize", "task_input": "Basic patterns are fast and cheap for straightforward prompts.", "constraints": {"max_latency_s": 1.6, "max_cost_usd": 0.002, "deny_arms": [], "w_quality": 1.0, "w_cost": 1.0, "w_latency": 0.2}}, "metrics": {"cpu_ms_small": 1.1145979997309041, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 1}, "explanation": "Chose reflective_agentic given context; tuned steps to 3. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 2, "arm": "llm_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.9277922077922078, "plan": {"framework": "LiteAgent", "tools": ["python_repl", "search", "retry"], "max_steps": 5, "task": "summarize", "task_input": "Reflective agents can retry and self-evaluate; graphs orchestrate multi-step reasoning.", "constraints": {"max_latency_s": 1.6, "max_cost_usd": 0.002, "deny_arms": [], "w_quality": 1.0, "w_cost": 1.0, "w_latency": 0.2}}, "metrics": {"cpu_ms_small": 0.5038980007157079, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 0}, "explanation": "Chose llm_agentic given context; tuned steps to 5. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 3, "arm": "graph_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.9277922077922078, "plan": {"framework": "GraphPlanner", "tools": ["router", "python_repl", "reflect", "retry", "search"], "max_steps": 5, "task": "summarize", "task_input": "BAAS selects among agent patterns to optimize quality, cost, and latency.", "constraints": {"max_latency_s": 1.6, "max_cost_usd": 0.002, "deny_arms": [], "w_quality": 1.0, "w_cost": 1.0, "w_latency": 0.2}}, "metrics": {"cpu_ms_small": 0.6587000007129973, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 0}, "explanation": "Chose graph_agentic given context; tuned steps to 5. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 4, "arm": "basic_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.001, "plan": {"framework": "LangChain", "tools": ["python_repl", "search"], "max_steps": 3, "task": "summarize", "task_input": "Reflective agents can retry and self-evaluate; graphs orchestrate multi-step reasoning.", "constraints": {"max_latency_s": 1.6, "max_cost_usd": 0.002, "deny_arms": [], "w_quality": 1.0, "w_cost": 1.0, "w_latency": 0.2}}, "metrics": {"cpu_ms_small": 0.6263719997150474, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 3, "smoke_pass": 1, "framework_langchain": 1, "framework_autogen": 0}, "explanation": "Chose basic_agentic given context; tuned steps to 3. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 5, "arm": "reflective_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.001, "plan": {"framework": "AutoGen", "tools": ["python_repl", "search", "retry", "reflect"], "max_steps": 3, "task": "summarize", "task_input": "Reflective agents can retry and self-evaluate; graphs orchestrate multi-step reasoning.", "constraints": {"max_latency_s": 1.6, "max_cost_usd": 0.002, "deny_arms": [], "w_quality": 1.0, "w_cost": 1.0, "w_latency": 0.2}}, "metrics": {"cpu_ms_small": 0.5508129997906508, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 1}, "explanation": "Chose reflective_agentic given context; tuned steps to 3. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 6, "arm": "llm_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.999, "plan": {"framework": "LiteAgent", "tools": ["python_repl", "search", "retry"], "max_steps": 5, "task": "summarize", "task_input": "Basic patterns are fast and cheap for straightforward prompts.", "constraints": {"max_latency_s": 1.6, "max_cost_usd": 0.002, "deny_arms": [], "w_quality": 1.0, "w_cost": 1.0, "w_latency": 0.2}}, "metrics": {"cpu_ms_small": 0.5728699998144293, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 0}, "explanation": "Chose llm_agentic given context; tuned steps to 5. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 7, "arm": "graph_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.999, "plan": {"framework": "GraphPlanner", "tools": ["router", "python_repl", "reflect", "retry", "search"], "max_steps": 5, "task": "summarize", "task_input": "Basic patterns are fast and cheap for straightforward prompts.", "constraints": {"max_latency_s": 1.6, "max_cost_usd": 0.002, "deny_arms": [], "w_quality": 1.0, "w_cost": 1.0, "w_latency": 0.2}}, "metrics": {"cpu_ms_small": 0.49069099986809306, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 0}, "explanation": "Chose graph_agentic given context; tuned steps to 5. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 8, "arm": "basic_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.001, "plan": {"framework": "LangChain", "tools": ["python_repl", "search"], "max_steps": 3, "task": "summarize", "task_input": "Basic patterns are fast and cheap for straightforward prompts.", "constraints": {"max_latency_s": 1.6, "max_cost_usd": 0.002, "deny_arms": [], "w_quality": 1.0, "w_cost": 1.0, "w_latency": 0.2}}, "metrics": {"cpu_ms_small": 0.581376999434724, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 3, "smoke_pass": 1, "framework_langchain": 1, "framework_autogen": 0}, "explanation": "Chose basic_agentic given context; tuned steps to 3. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 9, "arm": "reflective_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.001, "plan": {"framework": "AutoGen", "tools": ["python_repl", "search", "retry", "reflect"], "max_steps": 3, "task": "summarize", "task_input": "Reflective agents can retry and self-evaluate; graphs orchestrate multi-step reasoning.", "constraints": {"max_latency_s": 1.6, "max_cost_usd": 0.002, "deny_arms": [], "w_quality": 1.0, "w_cost": 1.0, "w_latency": 0.2}}, "metrics": {"cpu_ms_small": 0.5808269997942261, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 3, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 1}, "explanation": "Chose reflective_agentic given context; tuned steps to 3. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 10, "arm": "llm_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.999, "plan": {"framework": "LiteAgent", "tools": ["python_repl", "search", "retry"], "max_steps": 5, "task": "summarize", "task_input": "BAAS selects among agent patterns to optimize quality, cost, and latency.", "constraints": {"max_latency_s": 1.6, "max_cost_usd": 0.002, "deny_arms": [], "w_quality": 1.0, "w_cost": 1.0, "w_latency": 0.2}}, "metrics": {"cpu_ms_small": 0.5892810004297644, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 0}, "explanation": "Chose llm_agentic given context; tuned steps to 5. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 11, "arm": "graph_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.999, "plan": {"framework": "GraphPlanner", "tools": ["router", "python_repl", "reflect", "retry", "search"], "max_steps": 5, "task": "summarize", "task_input": "BAAS selects among agent patterns to optimize quality, cost, and latency.", "constraints": {"max_latency_s": 1.6, "max_cost_usd": 0.002, "deny_arms": [], "w_quality": 1.0, "w_cost": 1.0, "w_latency": 0.2}}, "metrics": {"cpu_ms_small": 0.49355600003764266, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 0}, "explanation": "Chose graph_agentic given context; tuned steps to 5. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 12, "arm": "basic_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.001, "plan": {"framework": "LangChain", "tools": ["python_repl", "search"], "max_steps": 3, "task": "summarize", "task_input": "BAAS selects among agent patterns to optimize quality, cost, and latency.", "constraints": {"max_latency_s": 1.6, "max_cost_usd": 0.002, "deny_arms": [], "w_quality": 1.0, "w_cost": 1.0, "w_latency": 0.2}}, "metrics": {"cpu_ms_small": 0.4774789995281026, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 3, "smoke_pass": 1, "framework_langchain": 1, "framework_autogen": 0}, "explanation": "Chose basic_agentic given context; tuned steps to 3. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 13, "arm": "reflective_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.001, "plan": {"framework": "AutoGen", "tools": ["python_repl", "search", "retry", "reflect"], "max_steps": 3, "task": "summarize", "task_input": "BAAS selects among agent patterns to optimize quality, cost, and latency.", "constraints": {"max_latency_s": 1.6, "max_cost_usd": 0.002, "deny_arms": [], "w_quality": 1.0, "w_cost": 1.0, "w_latency": 0.2}}, "metrics": {"cpu_ms_small": 0.5410660005509271, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 3, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 1}, "explanation": "Chose reflective_agentic given context; tuned steps to 3. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 14, "arm": "llm_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.999, "plan": {"framework": "LiteAgent", "tools": ["python_repl", "search", "retry"], "max_steps": 5, "task": "summarize", "task_input": "Basic patterns are fast and cheap for straightforward prompts.", "constraints": {"max_latency_s": 1.6, "max_cost_usd": 0.002, "deny_arms": [], "w_quality": 1.0, "w_cost": 1.0, "w_latency": 0.2}}, "metrics": {"cpu_ms_small": 0.5078109998066793, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 0}, "explanation": "Chose llm_agentic given context; tuned steps to 5. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 15, "arm": "graph_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.999, "plan": {"framework": "GraphPlanner", "tools": ["router", "python_repl", "reflect", "retry", "search"], "max_steps": 5, "task": "summarize", "task_input": "BAAS selects among agent patterns to optimize quality, cost, and latency.", "constraints": {"max_latency_s": 1.6, "max_cost_usd": 0.002, "deny_arms": [], "w_quality": 1.0, "w_cost": 1.0, "w_latency": 0.2}}, "metrics": {"cpu_ms_small": 0.6287780006459798, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 0}, "explanation": "Chose graph_agentic given context; tuned steps to 5. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 16, "arm": "basic_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.001, "plan": {"framework": "LangChain", "tools": ["python_repl", "search"], "max_steps": 3, "task": "summarize", "task_input": "Reflective agents can retry and self-evaluate; graphs orchestrate multi-step reasoning.", "constraints": {"max_latency_s": 1.6, "max_cost_usd": 0.002, "deny_arms": [], "w_quality": 1.0, "w_cost": 1.0, "w_latency": 0.2}}, "metrics": {"cpu_ms_small": 0.5829809997521807, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 3, "smoke_pass": 1, "framework_langchain": 1, "framework_autogen": 0}, "explanation": "Chose basic_agentic given context; tuned steps to 3. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 17, "arm": "reflective_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.001, "plan": {"framework": "AutoGen", "tools": ["python_repl", "search", "retry", "reflect"], "max_steps": 3, "task": "summarize", "task_input": "Reflective agents can retry and self-evaluate; graphs orchestrate multi-step reasoning.", "constraints": {"max_latency_s": 1.6, "max_cost_usd": 0.002, "deny_arms": [], "w_quality": 1.0, "w_cost": 1.0, "w_latency": 0.2}}, "metrics": {"cpu_ms_small": 0.5525209999177605, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 3, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 1}, "explanation": "Chose reflective_agentic given context; tuned steps to 3. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 18, "arm": "llm_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.999, "plan": {"framework": "LiteAgent", "tools": ["python_repl", "search", "retry"], "max_steps": 5, "task": "summarize", "task_input": "BAAS selects among agent patterns to optimize quality, cost, and latency.", "constraints": {"max_latency_s": 1.6, "max_cost_usd": 0.002, "deny_arms": [], "w_quality": 1.0, "w_cost": 1.0, "w_latency": 0.2}}, "metrics": {"cpu_ms_small": 0.6080240000301274, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 0}, "explanation": "Chose llm_agentic given context; tuned steps to 5. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 19, "arm": "graph_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.999, "plan": {"framework": "GraphPlanner", "tools": ["router", "python_repl", "reflect", "retry", "search"], "max_steps": 5, "task": "summarize", "task_input": "Basic patterns are fast and cheap for straightforward prompts.", "constraints": {"max_latency_s": 1.6, "max_cost_usd": 0.002, "deny_arms": [], "w_quality": 1.0, "w_cost": 1.0, "w_latency": 0.2}}, "metrics": {"cpu_ms_small": 0.5813919997308403, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 0}, "explanation": "Chose graph_agentic given context; tuned steps to 5. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 20, "arm": "basic_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.001, "plan": {"framework": "LangChain", "tools": ["python_repl", "search"], "max_steps": 3, "task": "summarize", "task_input": "BAAS selects among agent patterns to optimize quality, cost, and latency.", "constraints": {"max_latency_s": 1.6, "max_cost_usd": 0.002, "deny_arms": [], "w_quality": 1.0, "w_cost": 1.0, "w_latency": 0.2}}, "metrics": {"cpu_ms_small": 0.5553160008275881, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 3, "smoke_pass": 1, "framework_langchain": 1, "framework_autogen": 0}, "explanation": "Chose basic_agentic given context; tuned steps to 3. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 21, "arm": "reflective_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.001, "plan": {"framework": "AutoGen", "tools": ["python_repl", "search", "retry", "reflect"], "max_steps": 3, "task": "summarize", "task_input": "BAAS selects among agent patterns to optimize quality, cost, and latency.", "constraints": {"max_latency_s": 1.6, "max_cost_usd": 0.002, "deny_arms": [], "w_quality": 1.0, "w_cost": 1.0, "w_latency": 0.2}}, "metrics": {"cpu_ms_small": 0.5729810000048019, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 3, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 1}, "explanation": "Chose reflective_agentic given context; tuned steps to 3. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 22, "arm": "llm_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.999, "plan": {"framework": "LiteAgent", "tools": ["python_repl", "search", "retry"], "max_steps": 5, "task": "summarize", "task_input": "Reflective agents can retry and self-evaluate; graphs orchestrate multi-step reasoning.", "constraints": {"max_latency_s": 1.6, "max_cost_usd": 0.002, "deny_arms": [], "w_quality": 1.0, "w_cost": 1.0, "w_latency": 0.2}}, "metrics": {"cpu_ms_small": 0.5327690005287877, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 0}, "explanation": "Chose llm_agentic given context; tuned steps to 5. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 23, "arm": "graph_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.999, "plan": {"framework": "GraphPlanner", "tools": ["router", "python_repl", "reflect", "retry", "search"], "max_steps": 5, "task": "summarize", "task_input": "BAAS selects among agent patterns to optimize quality, cost, and latency.", "constraints": {"max_latency_s": 1.6, "max_cost_usd": 0.002, "deny_arms": [], "w_quality": 1.0, "w_cost": 1.0, "w_latency": 0.2}}, "metrics": {"cpu_ms_small": 0.6089020007493673, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 0}, "explanation": "Chose graph_agentic given context; tuned steps to 5. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 24, "arm": "basic_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.001, "plan": {"framework": "LangChain", "tools": ["python_repl", "search"], "max_steps": 3, "task": "summarize", "task_input": "BAAS selects among agent patterns to optimize quality, cost, and latency.", "constraints": {"max_latency_s": 1.6, "max_cost_usd": 0.002, "deny_arms": [], "w_quality": 1.0, "w_cost": 1.0, "w_latency": 0.2}}, "metrics": {"cpu_ms_small": 0.6315509999694768, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 3, "smoke_pass": 1, "framework_langchain": 1, "framework_autogen": 0}, "explanation": "Chose basic_agentic given context; tuned steps to 3. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 25, "arm": "reflective_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.001, "plan": {"framework": "AutoGen", "tools": ["python_repl", "search", "retry", "reflect"], "max_steps": 3, "task": "summarize", "task_input": "BAAS selects among agent patterns to optimize quality, cost, and latency.", "constraints": {"max_latency_s": 1.6, "max_cost_usd": 0.002, "deny_arms": [], "w_quality": 1.0, "w_cost": 1.0, "w_latency": 0.2}}, "metrics": {"cpu_ms_small": 0.5645070004902664, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 3, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 1}, "explanation": "Chose reflective_agentic given context; tuned steps to 3. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 26, "arm": "llm_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.999, "plan": {"framework": "LiteAgent", "tools": ["python_repl", "search", "retry"], "max_steps": 5, "task": "summarize", "task_input": "BAAS selects among agent patterns to optimize quality, cost, and latency.", "constraints": {"max_latency_s": 1.6, "max_cost_usd": 0.002, "deny_arms": [], "w_quality": 1.0, "w_cost": 1.0, "w_latency": 0.2}}, "metrics": {"cpu_ms_small": 0.5569670001932536, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 0}, "explanation": "Chose llm_agentic given context; tuned steps to 5. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 27, "arm": "graph_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.999, "plan": {"framework": "GraphPlanner", "tools": ["router", "python_repl", "reflect", "retry", "search"], "max_steps": 5, "task": "summarize", "task_input": "BAAS selects among agent patterns to optimize quality, cost, and latency.", "constraints": {"max_latency_s": 1.6, "max_cost_usd": 0.002, "deny_arms": [], "w_quality": 1.0, "w_cost": 1.0, "w_latency": 0.2}}, "metrics": {"cpu_ms_small": 0.6276080002862727, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 0}, "explanation": "Chose graph_agentic given context; tuned steps to 5. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 28, "arm": "basic_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.001, "plan": {"framework": "LangChain", "tools": ["python_repl", "search"], "max_steps": 3, "task": "summarize", "task_input": "Basic patterns are fast and cheap for straightforward prompts.", "constraints": {"max_latency_s": 1.6, "max_cost_usd": 0.002, "deny_arms": [], "w_quality": 1.0, "w_cost": 1.0, "w_latency": 0.2}}, "metrics": {"cpu_ms_small": 0.5769550007244106, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 3, "smoke_pass": 1, "framework_langchain": 1, "framework_autogen": 0}, "explanation": "Chose basic_agentic given context; tuned steps to 3. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 29, "arm": "reflective_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.001, "plan": {"framework": "AutoGen", "tools": ["python_repl", "search", "retry", "reflect"], "max_steps": 3, "task": "summarize", "task_input": "Basic patterns are fast and cheap for straightforward prompts.", "constraints": {"max_latency_s": 1.6, "max_cost_usd": 0.002, "deny_arms": [], "w_quality": 1.0, "w_cost": 1.0, "w_latency": 0.2}}, "metrics": {"cpu_ms_small": 0.6245229997148272, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 3, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 1}, "explanation": "Chose reflective_agentic given context; tuned steps to 3. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 0, "arm": "basic_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.05162420382165603, "plan": {"framework": "LangChain", "tools": ["python_repl", "search"], "max_steps": 3, "task": "summarize", "task_input": "Reflective agents can retry and self-evaluate; graphs orchestrate multi-step reasoning.", "prompt": "Summarize briefly in 1-2 sentences:\n\nReflective agents can retry and self-evaluate; graphs orchestrate multi-step reasoning."}, "metrics": {"cpu_ms_small": 0.5590769997070311, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 3, "smoke_pass": 1, "framework_langchain": 1, "framework_autogen": 0}, "explanation": "Chose basic_agentic given context; tuned steps to 3. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 1, "arm": "reflective_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.8115116279069767, "plan": {"framework": "AutoGen", "tools": ["python_repl", "search", "retry", "reflect"], "max_steps": 5, "task": "summarize", "task_input": "Basic patterns are fast and cheap for straightforward prompts.", "prompt": "Summarize briefly in 1-2 sentences:\n\nBasic patterns are fast and cheap for straightforward prompts."}, "metrics": {"cpu_ms_small": 0.6148149996079155, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 3, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 1}, "explanation": "Chose reflective_agentic given context; tuned steps to 5. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 0, "arm": "basic_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.18848837209302327, "plan": {"framework": "LangChain", "tools": ["python_repl", "search"], "max_steps": 3, "task": "summarize", "task_input": "Basic patterns are fast and cheap for straightforward prompts.", "prompt": "Summarize briefly in 1-2 sentences:\n\nBasic patterns are fast and cheap for straightforward prompts."}, "metrics": {"cpu_ms_small": 0.583674000154133, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 1, "framework_autogen": 0}, "explanation": "Chose basic_agentic given context; tuned steps to 3. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 1, "arm": "reflective_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.18848837209302327, "plan": {"framework": "AutoGen", "tools": ["python_repl", "search", "retry", "reflect"], "max_steps": 3, "task": "summarize", "task_input": "Basic patterns are fast and cheap for straightforward prompts.", "prompt": "Summarize briefly in 1-2 sentences:\n\nBasic patterns are fast and cheap for straightforward prompts."}, "metrics": {"cpu_ms_small": 0.55499000063719, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 1}, "explanation": "Chose reflective_agentic given context; tuned steps to 3. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 0, "arm": "basic_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.05162420382165603, "plan": {"framework": "LangChain", "tools": ["python_repl", "search"], "max_steps": 3, "task": "summarize", "task_input": "Reflective agents can retry and self-evaluate; graphs orchestrate multi-step reasoning.", "prompt": "Summarize briefly in 1-2 sentences:\n\nReflective agents can retry and self-evaluate; graphs orchestrate multi-step reasoning."}, "metrics": {"cpu_ms_small": 1.0174799999731476, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 3, "smoke_pass": 1, "framework_langchain": 1, "framework_autogen": 0}, "explanation": "Chose basic_agentic given context; tuned steps to 3. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 1, "arm": "reflective_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.05162420382165603, "plan": {"framework": "AutoGen", "tools": ["python_repl", "search", "retry", "reflect"], "max_steps": 3, "task": "summarize", "task_input": "Basic patterns are fast and cheap for straightforward prompts.", "prompt": "Summarize briefly in 1-2 sentences:\n\nBasic patterns are fast and cheap for straightforward prompts."}, "metrics": {"cpu_ms_small": 1.0271110004396178, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 3, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 1}, "explanation": "Chose reflective_agentic given context; tuned steps to 3. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 0, "arm": "basic_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.05162420382165603, "plan": {"framework": "LangChain", "tools": ["python_repl", "search"], "max_steps": 3, "task": "summarize", "task_input": "Basic patterns are fast and cheap for straightforward prompts.", "prompt": "Summarize briefly in 1-2 sentences:\n\nBasic patterns are fast and cheap for straightforward prompts."}, "metrics": {"cpu_ms_small": 0.5855690005773795, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 3, "smoke_pass": 1, "framework_langchain": 1, "framework_autogen": 0}, "explanation": "Chose basic_agentic given context; tuned steps to 3. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 1, "arm": "reflective_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.8115116279069767, "plan": {"framework": "AutoGen", "tools": ["python_repl", "search", "retry", "reflect"], "max_steps": 5, "task": "summarize", "task_input": "BAAS selects among agent patterns to optimize quality, cost, and latency.", "prompt": "Summarize briefly in 1-2 sentences:\n\nBAAS selects among agent patterns to optimize quality, cost, and latency."}, "metrics": {"cpu_ms_small": 0.6744259999322821, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 3, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 1}, "explanation": "Chose reflective_agentic given context; tuned steps to 5. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 2, "arm": "llm_agentic", "reward": 0.07777777777777777, "quality": 0.07777777777777777, "usd_cost": 0.000334, "latency_s": 1.2158467769622803, "tuned_p": 0.24173913043478257, "plan": {"framework": "LiteAgent", "tools": ["python_repl", "search", "retry"], "max_steps": 3, "_llm_metrics": {"llm_ok": 1, "llm_latency_s": 1.2158467769622803, "llm_out_len": 80, "llm_text": "{\"framework\":\"LiteAgent\",\"tools\":[\"python_repl\",\"search\",\"retry\"],\"max_steps\":6}", "usd_cost": 0.000334}, "task": "summarize", "task_input": "BAAS selects among agent patterns to optimize quality, cost, and latency.", "prompt": "Summarize briefly in 1-2 sentences:\n\nBAAS selects among agent patterns to optimize quality, cost, and latency."}, "metrics": {"cpu_ms_small": 0.5002999996577273, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 0, "llm_ok": 1, "llm_latency_s": 1.2158467769622803, "llm_out_len": 80, "llm_text": "{\"framework\":\"LiteAgent\",\"tools\":[\"python_repl\",\"search\",\"retry\"],\"max_steps\":6}", "usd_cost": 0.000334}, "explanation": "Chose llm_agentic given context; tuned steps to 3. Quality=0.08, Cost=$0.0003, Latency=1.22s."}
{"t": 3, "arm": "graph_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.9277922077922078, "plan": {"framework": "GraphPlanner", "tools": ["router", "python_repl", "reflect", "retry", "search"], "max_steps": 5, "task": "summarize", "task_input": "BAAS selects among agent patterns to optimize quality, cost, and latency.", "prompt": "Summarize briefly in 1-2 sentences:\n\nBAAS selects among agent patterns to optimize quality, cost, and latency."}, "metrics": {"cpu_ms_small": 0.5986779997328995, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 0}, "explanation": "Chose graph_agentic given context; tuned steps to 5. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 4, "arm": "basic_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.001, "plan": {"framework": "LangChain", "tools": ["python_repl", "search"], "max_steps": 3, "task": "summarize", "task_input": "BAAS selects among agent patterns to optimize quality, cost, and latency.", "prompt": "Summarize briefly in 1-2 sentences:\n\nBAAS selects among agent patterns to optimize quality, cost, and latency."}, "metrics": {"cpu_ms_small": 0.6243739999263198, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 3, "smoke_pass": 1, "framework_langchain": 1, "framework_autogen": 0}, "explanation": "Chose basic_agentic given context; tuned steps to 3. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 5, "arm": "reflective_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.999, "plan": {"framework": "AutoGen", "tools": ["python_repl", "search", "retry", "reflect"], "max_steps": 5, "task": "summarize", "task_input": "Reflective agents can retry and self-evaluate; graphs orchestrate multi-step reasoning.", "prompt": "Summarize briefly in 1-2 sentences:\n\nReflective agents can retry and self-evaluate; graphs orchestrate multi-step reasoning."}, "metrics": {"cpu_ms_small": 0.5432409998320509, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 1}, "explanation": "Chose reflective_agentic given context; tuned steps to 5. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 6, "arm": "graph_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.999, "plan": {"framework": "GraphPlanner", "tools": ["router", "python_repl", "reflect", "retry", "search"], "max_steps": 5, "task": "summarize", "task_input": "BAAS selects among agent patterns to optimize quality, cost, and latency.", "prompt": "Summarize briefly in 1-2 sentences:\n\nBAAS selects among agent patterns to optimize quality, cost, and latency."}, "metrics": {"cpu_ms_small": 0.8193510002456605, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 0}, "explanation": "Chose graph_agentic given context; tuned steps to 5. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 7, "arm": "llm_agentic", "reward": 0.0, "quality": 0.0, "usd_cost": 0.000334, "latency_s": 1.5630769729614258, "tuned_p": 0.9520308567912489, "plan": {"framework": "LiteAgent", "tools": ["python_repl", "search", "retry"], "max_steps": 5, "_llm_metrics": {"llm_ok": 1, "llm_latency_s": 1.5630769729614258, "llm_out_len": 80, "llm_text": "{\"framework\":\"LiteAgent\",\"tools\":[\"python_repl\",\"search\",\"retry\"],\"max_steps\":6}", "usd_cost": 0.000334}, "task": "summarize", "task_input": "Basic patterns are fast and cheap for straightforward prompts.", "prompt": "Summarize briefly in 1-2 sentences:\n\nBasic patterns are fast and cheap for straightforward prompts."}, "metrics": {"cpu_ms_small": 0.6034589996488648, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 0, "llm_ok": 1, "llm_latency_s": 1.5630769729614258, "llm_out_len": 80, "llm_text": "{\"framework\":\"LiteAgent\",\"tools\":[\"python_repl\",\"search\",\"retry\"],\"max_steps\":6}", "usd_cost": 0.000334}, "explanation": "Chose llm_agentic given context; tuned steps to 5. Quality=0.00, Cost=$0.0003, Latency=1.56s."}
{"t": 8, "arm": "basic_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.001, "plan": {"framework": "LangChain", "tools": ["python_repl", "search"], "max_steps": 3, "task": "summarize", "task_input": "Basic patterns are fast and cheap for straightforward prompts.", "prompt": "Summarize briefly in 1-2 sentences:\n\nBasic patterns are fast and cheap for straightforward prompts."}, "metrics": {"cpu_ms_small": 0.5775580002591596, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 3, "smoke_pass": 1, "framework_langchain": 1, "framework_autogen": 0}, "explanation": "Chose basic_agentic given context; tuned steps to 3. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 9, "arm": "reflective_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.999, "plan": {"framework": "AutoGen", "tools": ["python_repl", "search", "retry", "reflect"], "max_steps": 5, "task": "summarize", "task_input": "BAAS selects among agent patterns to optimize quality, cost, and latency.", "prompt": "Summarize briefly in 1-2 sentences:\n\nBAAS selects among agent patterns to optimize quality, cost, and latency."}, "metrics": {"cpu_ms_small": 0.5318390003594686, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 1}, "explanation": "Chose reflective_agentic given context; tuned steps to 5. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 10, "arm": "graph_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.999, "plan": {"framework": "GraphPlanner", "tools": ["router", "python_repl", "reflect", "retry", "search"], "max_steps": 5, "task": "summarize", "task_input": "Reflective agents can retry and self-evaluate; graphs orchestrate multi-step reasoning.", "prompt": "Summarize briefly in 1-2 sentences:\n\nReflective agents can retry and self-evaluate; graphs orchestrate multi-step reasoning."}, "metrics": {"cpu_ms_small": 0.5750580003223149, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 0}, "explanation": "Chose graph_agentic given context; tuned steps to 5. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 11, "arm": "basic_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.001, "plan": {"framework": "LangChain", "tools": ["python_repl", "search"], "max_steps": 3, "task": "summarize", "task_input": "Reflective agents can retry and self-evaluate; graphs orchestrate multi-step reasoning.", "prompt": "Summarize briefly in 1-2 sentences:\n\nReflective agents can retry and self-evaluate; graphs orchestrate multi-step reasoning."}, "metrics": {"cpu_ms_small": 0.7635829997525434, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 3, "smoke_pass": 1, "framework_langchain": 1, "framework_autogen": 0}, "explanation": "Chose basic_agentic given context; tuned steps to 3. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 12, "arm": "reflective_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.999, "plan": {"framework": "AutoGen", "tools": ["python_repl", "search", "retry", "reflect"], "max_steps": 5, "task": "summarize", "task_input": "Basic patterns are fast and cheap for straightforward prompts.", "prompt": "Summarize briefly in 1-2 sentences:\n\nBasic patterns are fast and cheap for straightforward prompts."}, "metrics": {"cpu_ms_small": 0.521481999385287, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 1}, "explanation": "Chose reflective_agentic given context; tuned steps to 5. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 13, "arm": "graph_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.999, "plan": {"framework": "GraphPlanner", "tools": ["router", "python_repl", "reflect", "retry", "search"], "max_steps": 5, "task": "summarize", "task_input": "Reflective agents can retry and self-evaluate; graphs orchestrate multi-step reasoning.", "prompt": "Summarize briefly in 1-2 sentences:\n\nReflective agents can retry and self-evaluate; graphs orchestrate multi-step reasoning."}, "metrics": {"cpu_ms_small": 0.5650490002153674, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 0}, "explanation": "Chose graph_agentic given context; tuned steps to 5. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 14, "arm": "basic_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.001, "plan": {"framework": "LangChain", "tools": ["python_repl", "search"], "max_steps": 3, "task": "summarize", "task_input": "Basic patterns are fast and cheap for straightforward prompts.", "prompt": "Summarize briefly in 1-2 sentences:\n\nBasic patterns are fast and cheap for straightforward prompts."}, "metrics": {"cpu_ms_small": 0.7676559998799348, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 3, "smoke_pass": 1, "framework_langchain": 1, "framework_autogen": 0}, "explanation": "Chose basic_agentic given context; tuned steps to 3. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 15, "arm": "reflective_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.999, "plan": {"framework": "AutoGen", "tools": ["python_repl", "search", "retry", "reflect"], "max_steps": 5, "task": "summarize", "task_input": "Basic patterns are fast and cheap for straightforward prompts.", "prompt": "Summarize briefly in 1-2 sentences:\n\nBasic patterns are fast and cheap for straightforward prompts."}, "metrics": {"cpu_ms_small": 0.720166000064637, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 1}, "explanation": "Chose reflective_agentic given context; tuned steps to 5. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 16, "arm": "graph_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.999, "plan": {"framework": "GraphPlanner", "tools": ["router", "python_repl", "reflect", "retry", "search"], "max_steps": 5, "task": "summarize", "task_input": "BAAS selects among agent patterns to optimize quality, cost, and latency.", "prompt": "Summarize briefly in 1-2 sentences:\n\nBAAS selects among agent patterns to optimize quality, cost, and latency."}, "metrics": {"cpu_ms_small": 0.5676020000464632, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 0}, "explanation": "Chose graph_agentic given context; tuned steps to 5. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 17, "arm": "basic_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.001, "plan": {"framework": "LangChain", "tools": ["python_repl", "search"], "max_steps": 3, "task": "summarize", "task_input": "Reflective agents can retry and self-evaluate; graphs orchestrate multi-step reasoning.", "prompt": "Summarize briefly in 1-2 sentences:\n\nReflective agents can retry and self-evaluate; graphs orchestrate multi-step reasoning."}, "metrics": {"cpu_ms_small": 0.794958000369661, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 3, "smoke_pass": 1, "framework_langchain": 1, "framework_autogen": 0}, "explanation": "Chose basic_agentic given context; tuned steps to 3. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 18, "arm": "reflective_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.999, "plan": {"framework": "AutoGen", "tools": ["python_repl", "search", "retry", "reflect"], "max_steps": 5, "task": "summarize", "task_input": "Basic patterns are fast and cheap for straightforward prompts.", "prompt": "Summarize briefly in 1-2 sentences:\n\nBasic patterns are fast and cheap for straightforward prompts."}, "metrics": {"cpu_ms_small": 0.8085590006885468, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 1}, "explanation": "Chose reflective_agentic given context; tuned steps to 5. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 19, "arm": "graph_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.999, "plan": {"framework": "GraphPlanner", "tools": ["router", "python_repl", "reflect", "retry", "search"], "max_steps": 5, "task": "summarize", "task_input": "Basic patterns are fast and cheap for straightforward prompts.", "prompt": "Summarize briefly in 1-2 sentences:\n\nBasic patterns are fast and cheap for straightforward prompts."}, "metrics": {"cpu_ms_small": 0.5022960003771004, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 0}, "explanation": "Chose graph_agentic given context; tuned steps to 5. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 20, "arm": "llm_agentic", "reward": 0.12727272727272726, "quality": 0.12727272727272726, "usd_cost": 0.000334, "latency_s": 0.9908092021942139, "tuned_p": 0.999, "plan": {"framework": "LiteAgent", "tools": ["python_repl", "search", "retry"], "max_steps": 5, "_llm_metrics": {"llm_ok": 1, "llm_latency_s": 0.9908092021942139, "llm_out_len": 80, "llm_text": "{\"framework\":\"LiteAgent\",\"tools\":[\"python_repl\",\"search\",\"retry\"],\"max_steps\":6}", "usd_cost": 0.000334}, "task": "summarize", "task_input": "Reflective agents can retry and self-evaluate; graphs orchestrate multi-step reasoning.", "prompt": "Summarize briefly in 1-2 sentences:\n\nReflective agents can retry and self-evaluate; graphs orchestrate multi-step reasoning."}, "metrics": {"cpu_ms_small": 0.6454620006479672, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 0, "llm_ok": 1, "llm_latency_s": 0.9908092021942139, "llm_out_len": 80, "llm_text": "{\"framework\":\"LiteAgent\",\"tools\":[\"python_repl\",\"search\",\"retry\"],\"max_steps\":6}", "usd_cost": 0.000334}, "explanation": "Chose llm_agentic given context; tuned steps to 5. Quality=0.13, Cost=$0.0003, Latency=0.99s."}
{"t": 21, "arm": "basic_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.001, "plan": {"framework": "LangChain", "tools": ["python_repl", "search"], "max_steps": 3, "task": "summarize", "task_input": "Reflective agents can retry and self-evaluate; graphs orchestrate multi-step reasoning.", "prompt": "Summarize briefly in 1-2 sentences:\n\nReflective agents can retry and self-evaluate; graphs orchestrate multi-step reasoning."}, "metrics": {"cpu_ms_small": 0.5715620000046329, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 3, "smoke_pass": 1, "framework_langchain": 1, "framework_autogen": 0}, "explanation": "Chose basic_agentic given context; tuned steps to 3. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 22, "arm": "reflective_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.999, "plan": {"framework": "AutoGen", "tools": ["python_repl", "search", "retry", "reflect"], "max_steps": 5, "task": "summarize", "task_input": "Basic patterns are fast and cheap for straightforward prompts.", "prompt": "Summarize briefly in 1-2 sentences:\n\nBasic patterns are fast and cheap for straightforward prompts."}, "metrics": {"cpu_ms_small": 0.7312630004889797, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 1}, "explanation": "Chose reflective_agentic given context; tuned steps to 5. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 23, "arm": "graph_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.999, "plan": {"framework": "GraphPlanner", "tools": ["router", "python_repl", "reflect", "retry", "search"], "max_steps": 5, "task": "summarize", "task_input": "Reflective agents can retry and self-evaluate; graphs orchestrate multi-step reasoning.", "prompt": "Summarize briefly in 1-2 sentences:\n\nReflective agents can retry and self-evaluate; graphs orchestrate multi-step reasoning."}, "metrics": {"cpu_ms_small": 0.5978900007903576, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 0}, "explanation": "Chose graph_agentic given context; tuned steps to 5. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 24, "arm": "basic_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.001, "plan": {"framework": "LangChain", "tools": ["python_repl", "search"], "max_steps": 3, "task": "summarize", "task_input": "Reflective agents can retry and self-evaluate; graphs orchestrate multi-step reasoning.", "prompt": "Summarize briefly in 1-2 sentences:\n\nReflective agents can retry and self-evaluate; graphs orchestrate multi-step reasoning."}, "metrics": {"cpu_ms_small": 0.8974820002549677, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 3, "smoke_pass": 1, "framework_langchain": 1, "framework_autogen": 0}, "explanation": "Chose basic_agentic given context; tuned steps to 3. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 25, "arm": "reflective_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.999, "plan": {"framework": "AutoGen", "tools": ["python_repl", "search", "retry", "reflect"], "max_steps": 5, "task": "summarize", "task_input": "Reflective agents can retry and self-evaluate; graphs orchestrate multi-step reasoning.", "prompt": "Summarize briefly in 1-2 sentences:\n\nReflective agents can retry and self-evaluate; graphs orchestrate multi-step reasoning."}, "metrics": {"cpu_ms_small": 0.6166479997773422, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 1}, "explanation": "Chose reflective_agentic given context; tuned steps to 5. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 26, "arm": "graph_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.999, "plan": {"framework": "GraphPlanner", "tools": ["router", "python_repl", "reflect", "retry", "search"], "max_steps": 5, "task": "summarize", "task_input": "BAAS selects among agent patterns to optimize quality, cost, and latency.", "prompt": "Summarize briefly in 1-2 sentences:\n\nBAAS selects among agent patterns to optimize quality, cost, and latency."}, "metrics": {"cpu_ms_small": 0.6189549994815025, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 0}, "explanation": "Chose graph_agentic given context; tuned steps to 5. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 27, "arm": "basic_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.001, "plan": {"framework": "LangChain", "tools": ["python_repl", "search"], "max_steps": 3, "task": "summarize", "task_input": "Reflective agents can retry and self-evaluate; graphs orchestrate multi-step reasoning.", "prompt": "Summarize briefly in 1-2 sentences:\n\nReflective agents can retry and self-evaluate; graphs orchestrate multi-step reasoning."}, "metrics": {"cpu_ms_small": 1.4238869998735026, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 3, "smoke_pass": 1, "framework_langchain": 1, "framework_autogen": 0}, "explanation": "Chose basic_agentic given context; tuned steps to 3. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 28, "arm": "reflective_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.999, "plan": {"framework": "AutoGen", "tools": ["python_repl", "search", "retry", "reflect"], "max_steps": 5, "task": "summarize", "task_input": "Reflective agents can retry and self-evaluate; graphs orchestrate multi-step reasoning.", "prompt": "Summarize briefly in 1-2 sentences:\n\nReflective agents can retry and self-evaluate; graphs orchestrate multi-step reasoning."}, "metrics": {"cpu_ms_small": 0.5470429996421444, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 1}, "explanation": "Chose reflective_agentic given context; tuned steps to 5. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 29, "arm": "graph_agentic", "reward": 0.3, "quality": 0.3, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.999, "plan": {"framework": "GraphPlanner", "tools": ["router", "python_repl", "reflect", "retry", "search"], "max_steps": 5, "task": "summarize", "task_input": "Basic patterns are fast and cheap for straightforward prompts.", "prompt": "Summarize briefly in 1-2 sentences:\n\nBasic patterns are fast and cheap for straightforward prompts."}, "metrics": {"cpu_ms_small": 0.5580999995800084, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 0}, "explanation": "Chose graph_agentic given context; tuned steps to 5. Quality=0.30, Cost=$0.0000, Latency=0.00s."}
{"t": 0, "arm": "basic_agentic", "reward": 0.1, "quality": 0.1, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.05162420382165603, "plan": {"framework": "LangChain", "tools": ["python_repl", "search"], "max_steps": 3, "task": "summarize", "task_input": "BAAS selects among agent patterns to optimize quality, cost, and latency.", "constraints": {"max_latency_s": 2.0, "max_cost_usd": 0.01, "deny_arms": [], "w_quality": 1.0, "w_cost": 0.1, "w_latency": 0.1}}, "metrics": {"cpu_ms_small": 0.57136499981425, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 3, "smoke_pass": 1, "framework_langchain": 1, "framework_autogen": 0}, "explanation": "Chose basic_agentic given context; tuned steps to 3. Quality=0.10, Cost=$0.0000, Latency=0.00s."}
{"t": 1, "arm": "reflective_agentic", "reward": 0.1, "quality": 0.1, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.948375796178344, "plan": {"framework": "AutoGen", "tools": ["python_repl", "search", "retry", "reflect"], "max_steps": 5, "task": "summarize", "task_input": "Reflective agents can retry and self-evaluate; graphs orchestrate multi-step reasoning.", "constraints": {"max_latency_s": 2.0, "max_cost_usd": 0.01, "deny_arms": [], "w_quality": 1.0, "w_cost": 0.1, "w_latency": 0.1}}, "metrics": {"cpu_ms_small": 0.5511939998541493, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 1}, "explanation": "Chose reflective_agentic given context; tuned steps to 5. Quality=0.10, Cost=$0.0000, Latency=0.00s."}
{"t": 2, "arm": "llm_agentic", "reward": 0.0, "quality": 5.594217588506538e-21, "usd_cost": 0.000334, "latency_s": 0.0, "tuned_p": 0.07220779220779219, "plan": {"framework": "LiteAgent", "tools": ["python_repl", "search", "retry"], "max_steps": 3, "_llm_metrics": {"llm_ok": 1, "llm_latency_s": 1.1354575157165527, "llm_out_len": 80, "llm_text": "{\"framework\":\"LiteAgent\",\"tools\":[\"python_repl\",\"search\",\"retry\"],\"max_steps\":6}", "usd_cost": 0.000334}, "task": "summarize", "task_input": "BAAS selects among agent patterns to optimize quality, cost, and latency.", "constraints": {"max_latency_s": 2.0, "max_cost_usd": 0.01, "deny_arms": [], "w_quality": 1.0, "w_cost": 0.1, "w_latency": 0.1}}, "metrics": {"cpu_ms_small": 1.0726579994297936, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 3, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 0, "llm_ok": 1, "llm_latency_s": 1.1354575157165527, "llm_out_len": 80, "llm_text": "{\"framework\":\"LiteAgent\",\"tools\":[\"python_repl\",\"search\",\"retry\"],\"max_steps\":6}", "usd_cost": 0.000334}, "explanation": "Chose llm_agentic given context; tuned steps to 3. Quality=0.00, Cost=$0.0003, Latency=0.00s."}
{"t": 3, "arm": "graph_agentic", "reward": 0.1, "quality": 0.1, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.9277922077922078, "plan": {"framework": "GraphPlanner", "tools": ["router", "python_repl", "reflect", "retry", "search"], "max_steps": 5, "task": "summarize", "task_input": "Basic patterns are fast and cheap for straightforward prompts.", "constraints": {"max_latency_s": 2.0, "max_cost_usd": 0.01, "deny_arms": [], "w_quality": 1.0, "w_cost": 0.1, "w_latency": 0.1}}, "metrics": {"cpu_ms_small": 0.6231939996723668, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 0}, "explanation": "Chose graph_agentic given context; tuned steps to 5. Quality=0.10, Cost=$0.0000, Latency=0.00s."}
{"t": 4, "arm": "basic_agentic", "reward": 0.1, "quality": 0.1, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.001, "plan": {"framework": "LangChain", "tools": ["python_repl", "search"], "max_steps": 3, "task": "summarize", "task_input": "BAAS selects among agent patterns to optimize quality, cost, and latency.", "constraints": {"max_latency_s": 2.0, "max_cost_usd": 0.01, "deny_arms": [], "w_quality": 1.0, "w_cost": 0.1, "w_latency": 0.1}}, "metrics": {"cpu_ms_small": 1.1842200001410674, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 3, "smoke_pass": 1, "framework_langchain": 1, "framework_autogen": 0}, "explanation": "Chose basic_agentic given context; tuned steps to 3. Quality=0.10, Cost=$0.0000, Latency=0.00s."}
{"t": 5, "arm": "reflective_agentic", "reward": 0.1, "quality": 0.1, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.999, "plan": {"framework": "AutoGen", "tools": ["python_repl", "search", "retry", "reflect"], "max_steps": 5, "task": "summarize", "task_input": "Basic patterns are fast and cheap for straightforward prompts.", "constraints": {"max_latency_s": 2.0, "max_cost_usd": 0.01, "deny_arms": [], "w_quality": 1.0, "w_cost": 0.1, "w_latency": 0.1}}, "metrics": {"cpu_ms_small": 1.1249190001763054, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 1}, "explanation": "Chose reflective_agentic given context; tuned steps to 5. Quality=0.10, Cost=$0.0000, Latency=0.00s."}
{"t": 6, "arm": "graph_agentic", "reward": 0.1, "quality": 0.1, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.999, "plan": {"framework": "GraphPlanner", "tools": ["router", "python_repl", "reflect", "retry", "search"], "max_steps": 5, "task": "summarize", "task_input": "Basic patterns are fast and cheap for straightforward prompts.", "constraints": {"max_latency_s": 2.0, "max_cost_usd": 0.01, "deny_arms": [], "w_quality": 1.0, "w_cost": 0.1, "w_latency": 0.1}}, "metrics": {"cpu_ms_small": 1.1554400007298682, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 0}, "explanation": "Chose graph_agentic given context; tuned steps to 5. Quality=0.10, Cost=$0.0000, Latency=0.00s."}
{"t": 7, "arm": "llm_agentic", "reward": 0.0, "quality": 8.70287480533955e-30, "usd_cost": 0.000334, "latency_s": 0.0, "tuned_p": 0.999, "plan": {"framework": "LiteAgent", "tools": ["python_repl", "search", "retry"], "max_steps": 5, "_llm_metrics": {"llm_ok": 1, "llm_latency_s": 0.9264693260192871, "llm_out_len": 80, "llm_text": "{\"framework\":\"LiteAgent\",\"tools\":[\"python_repl\",\"search\",\"retry\"],\"max_steps\":6}", "usd_cost": 0.000334}, "task": "summarize", "task_input": "Basic patterns are fast and cheap for straightforward prompts.", "constraints": {"max_latency_s": 2.0, "max_cost_usd": 0.01, "deny_arms": [], "w_quality": 1.0, "w_cost": 0.1, "w_latency": 0.1}}, "metrics": {"cpu_ms_small": 0.47156799973890884, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 0, "llm_ok": 1, "llm_latency_s": 0.9264693260192871, "llm_out_len": 80, "llm_text": "{\"framework\":\"LiteAgent\",\"tools\":[\"python_repl\",\"search\",\"retry\"],\"max_steps\":6}", "usd_cost": 0.000334}, "explanation": "Chose llm_agentic given context; tuned steps to 5. Quality=0.00, Cost=$0.0003, Latency=0.00s."}
{"t": 8, "arm": "basic_agentic", "reward": 0.1, "quality": 0.1, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.001, "plan": {"framework": "LangChain", "tools": ["python_repl", "search"], "max_steps": 3, "task": "summarize", "task_input": "Basic patterns are fast and cheap for straightforward prompts.", "constraints": {"max_latency_s": 2.0, "max_cost_usd": 0.01, "deny_arms": [], "w_quality": 1.0, "w_cost": 0.1, "w_latency": 0.1}}, "metrics": {"cpu_ms_small": 0.46589300018240465, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 3, "smoke_pass": 1, "framework_langchain": 1, "framework_autogen": 0}, "explanation": "Chose basic_agentic given context; tuned steps to 3. Quality=0.10, Cost=$0.0000, Latency=0.00s."}
{"t": 9, "arm": "reflective_agentic", "reward": 0.1, "quality": 0.1, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.999, "plan": {"framework": "AutoGen", "tools": ["python_repl", "search", "retry", "reflect"], "max_steps": 5, "task": "summarize", "task_input": "Reflective agents can retry and self-evaluate; graphs orchestrate multi-step reasoning.", "constraints": {"max_latency_s": 2.0, "max_cost_usd": 0.01, "deny_arms": [], "w_quality": 1.0, "w_cost": 0.1, "w_latency": 0.1}}, "metrics": {"cpu_ms_small": 0.5850170000485377, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 1}, "explanation": "Chose reflective_agentic given context; tuned steps to 5. Quality=0.10, Cost=$0.0000, Latency=0.00s."}
{"t": 10, "arm": "graph_agentic", "reward": 0.1, "quality": 0.1, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.999, "plan": {"framework": "GraphPlanner", "tools": ["router", "python_repl", "reflect", "retry", "search"], "max_steps": 5, "task": "summarize", "task_input": "Reflective agents can retry and self-evaluate; graphs orchestrate multi-step reasoning.", "constraints": {"max_latency_s": 2.0, "max_cost_usd": 0.01, "deny_arms": [], "w_quality": 1.0, "w_cost": 0.1, "w_latency": 0.1}}, "metrics": {"cpu_ms_small": 0.586741000006441, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 0}, "explanation": "Chose graph_agentic given context; tuned steps to 5. Quality=0.10, Cost=$0.0000, Latency=0.00s."}
{"t": 11, "arm": "llm_agentic", "reward": 0.0, "quality": 8.70287480533955e-30, "usd_cost": 0.000334, "latency_s": 0.0, "tuned_p": 0.999, "plan": {"framework": "LiteAgent", "tools": ["python_repl", "search", "retry"], "max_steps": 5, "_llm_metrics": {"llm_ok": 1, "llm_latency_s": 1.0005688667297363, "llm_out_len": 80, "llm_text": "{\"framework\":\"LiteAgent\",\"tools\":[\"python_repl\",\"search\",\"retry\"],\"max_steps\":6}", "usd_cost": 0.000334}, "task": "summarize", "task_input": "Basic patterns are fast and cheap for straightforward prompts.", "constraints": {"max_latency_s": 2.0, "max_cost_usd": 0.01, "deny_arms": [], "w_quality": 1.0, "w_cost": 0.1, "w_latency": 0.1}}, "metrics": {"cpu_ms_small": 0.6033290001141722, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 0, "llm_ok": 1, "llm_latency_s": 1.0005688667297363, "llm_out_len": 80, "llm_text": "{\"framework\":\"LiteAgent\",\"tools\":[\"python_repl\",\"search\",\"retry\"],\"max_steps\":6}", "usd_cost": 0.000334}, "explanation": "Chose llm_agentic given context; tuned steps to 5. Quality=0.00, Cost=$0.0003, Latency=0.00s."}
{"t": 12, "arm": "basic_agentic", "reward": 0.1, "quality": 0.1, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.001, "plan": {"framework": "LangChain", "tools": ["python_repl", "search"], "max_steps": 3, "task": "summarize", "task_input": "Reflective agents can retry and self-evaluate; graphs orchestrate multi-step reasoning.", "constraints": {"max_latency_s": 2.0, "max_cost_usd": 0.01, "deny_arms": [], "w_quality": 1.0, "w_cost": 0.1, "w_latency": 0.1}}, "metrics": {"cpu_ms_small": 0.643936000415124, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 3, "smoke_pass": 1, "framework_langchain": 1, "framework_autogen": 0}, "explanation": "Chose basic_agentic given context; tuned steps to 3. Quality=0.10, Cost=$0.0000, Latency=0.00s."}
{"t": 13, "arm": "reflective_agentic", "reward": 0.1, "quality": 0.1, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.999, "plan": {"framework": "AutoGen", "tools": ["python_repl", "search", "retry", "reflect"], "max_steps": 5, "task": "summarize", "task_input": "BAAS selects among agent patterns to optimize quality, cost, and latency.", "constraints": {"max_latency_s": 2.0, "max_cost_usd": 0.01, "deny_arms": [], "w_quality": 1.0, "w_cost": 0.1, "w_latency": 0.1}}, "metrics": {"cpu_ms_small": 0.9406529998159385, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 1}, "explanation": "Chose reflective_agentic given context; tuned steps to 5. Quality=0.10, Cost=$0.0000, Latency=0.00s."}
{"t": 14, "arm": "graph_agentic", "reward": 0.1, "quality": 0.1, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.999, "plan": {"framework": "GraphPlanner", "tools": ["router", "python_repl", "reflect", "retry", "search"], "max_steps": 5, "task": "summarize", "task_input": "Reflective agents can retry and self-evaluate; graphs orchestrate multi-step reasoning.", "constraints": {"max_latency_s": 2.0, "max_cost_usd": 0.01, "deny_arms": [], "w_quality": 1.0, "w_cost": 0.1, "w_latency": 0.1}}, "metrics": {"cpu_ms_small": 0.5318350004017702, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 0}, "explanation": "Chose graph_agentic given context; tuned steps to 5. Quality=0.10, Cost=$0.0000, Latency=0.00s."}
{"t": 15, "arm": "basic_agentic", "reward": 0.1, "quality": 0.1, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.001, "plan": {"framework": "LangChain", "tools": ["python_repl", "search"], "max_steps": 3, "task": "summarize", "task_input": "BAAS selects among agent patterns to optimize quality, cost, and latency.", "constraints": {"max_latency_s": 2.0, "max_cost_usd": 0.01, "deny_arms": [], "w_quality": 1.0, "w_cost": 0.1, "w_latency": 0.1}}, "metrics": {"cpu_ms_small": 2.186761999837472, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 3, "smoke_pass": 1, "framework_langchain": 1, "framework_autogen": 0}, "explanation": "Chose basic_agentic given context; tuned steps to 3. Quality=0.10, Cost=$0.0000, Latency=0.00s."}
{"t": 16, "arm": "reflective_agentic", "reward": 0.1, "quality": 0.1, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.999, "plan": {"framework": "AutoGen", "tools": ["python_repl", "search", "retry", "reflect"], "max_steps": 5, "task": "summarize", "task_input": "BAAS selects among agent patterns to optimize quality, cost, and latency.", "constraints": {"max_latency_s": 2.0, "max_cost_usd": 0.01, "deny_arms": [], "w_quality": 1.0, "w_cost": 0.1, "w_latency": 0.1}}, "metrics": {"cpu_ms_small": 1.2774520000675693, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 1}, "explanation": "Chose reflective_agentic given context; tuned steps to 5. Quality=0.10, Cost=$0.0000, Latency=0.00s."}
{"t": 17, "arm": "graph_agentic", "reward": 0.1, "quality": 0.1, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.999, "plan": {"framework": "GraphPlanner", "tools": ["router", "python_repl", "reflect", "retry", "search"], "max_steps": 5, "task": "summarize", "task_input": "Basic patterns are fast and cheap for straightforward prompts.", "constraints": {"max_latency_s": 2.0, "max_cost_usd": 0.01, "deny_arms": [], "w_quality": 1.0, "w_cost": 0.1, "w_latency": 0.1}}, "metrics": {"cpu_ms_small": 0.9810789997573011, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 0}, "explanation": "Chose graph_agentic given context; tuned steps to 5. Quality=0.10, Cost=$0.0000, Latency=0.00s."}
{"t": 18, "arm": "llm_agentic", "reward": 0.0, "quality": 5.594217588506538e-21, "usd_cost": 0.000334, "latency_s": 0.0, "tuned_p": 0.999, "plan": {"framework": "LiteAgent", "tools": ["python_repl", "search", "retry"], "max_steps": 5, "_llm_metrics": {"llm_ok": 1, "llm_latency_s": 1.0063457489013672, "llm_out_len": 80, "llm_text": "{\"framework\":\"LiteAgent\",\"tools\":[\"python_repl\",\"search\",\"retry\"],\"max_steps\":6}", "usd_cost": 0.000334}, "task": "summarize", "task_input": "BAAS selects among agent patterns to optimize quality, cost, and latency.", "constraints": {"max_latency_s": 2.0, "max_cost_usd": 0.01, "deny_arms": [], "w_quality": 1.0, "w_cost": 0.1, "w_latency": 0.1}}, "metrics": {"cpu_ms_small": 1.114146999498189, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 0, "llm_ok": 1, "llm_latency_s": 1.0063457489013672, "llm_out_len": 80, "llm_text": "{\"framework\":\"LiteAgent\",\"tools\":[\"python_repl\",\"search\",\"retry\"],\"max_steps\":6}", "usd_cost": 0.000334}, "explanation": "Chose llm_agentic given context; tuned steps to 5. Quality=0.00, Cost=$0.0003, Latency=0.00s."}
{"t": 19, "arm": "basic_agentic", "reward": 0.1, "quality": 0.1, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.001, "plan": {"framework": "LangChain", "tools": ["python_repl", "search"], "max_steps": 3, "task": "summarize", "task_input": "Reflective agents can retry and self-evaluate; graphs orchestrate multi-step reasoning.", "constraints": {"max_latency_s": 2.0, "max_cost_usd": 0.01, "deny_arms": [], "w_quality": 1.0, "w_cost": 0.1, "w_latency": 0.1}}, "metrics": {"cpu_ms_small": 1.5121989999897778, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 3, "smoke_pass": 1, "framework_langchain": 1, "framework_autogen": 0}, "explanation": "Chose basic_agentic given context; tuned steps to 3. Quality=0.10, Cost=$0.0000, Latency=0.00s."}
{"t": 20, "arm": "reflective_agentic", "reward": 0.1, "quality": 0.1, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.999, "plan": {"framework": "AutoGen", "tools": ["python_repl", "search", "retry", "reflect"], "max_steps": 5, "task": "summarize", "task_input": "Reflective agents can retry and self-evaluate; graphs orchestrate multi-step reasoning.", "constraints": {"max_latency_s": 2.0, "max_cost_usd": 0.01, "deny_arms": [], "w_quality": 1.0, "w_cost": 0.1, "w_latency": 0.1}}, "metrics": {"cpu_ms_small": 3.1869439999354654, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 1}, "explanation": "Chose reflective_agentic given context; tuned steps to 5. Quality=0.10, Cost=$0.0000, Latency=0.00s."}
{"t": 21, "arm": "graph_agentic", "reward": 0.1, "quality": 0.1, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.999, "plan": {"framework": "GraphPlanner", "tools": ["router", "python_repl", "reflect", "retry", "search"], "max_steps": 5, "task": "summarize", "task_input": "Reflective agents can retry and self-evaluate; graphs orchestrate multi-step reasoning.", "constraints": {"max_latency_s": 2.0, "max_cost_usd": 0.01, "deny_arms": [], "w_quality": 1.0, "w_cost": 0.1, "w_latency": 0.1}}, "metrics": {"cpu_ms_small": 1.0780550001072697, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 0}, "explanation": "Chose graph_agentic given context; tuned steps to 5. Quality=0.10, Cost=$0.0000, Latency=0.00s."}
{"t": 22, "arm": "basic_agentic", "reward": 0.1, "quality": 0.1, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.001, "plan": {"framework": "LangChain", "tools": ["python_repl", "search"], "max_steps": 3, "task": "summarize", "task_input": "Reflective agents can retry and self-evaluate; graphs orchestrate multi-step reasoning.", "constraints": {"max_latency_s": 2.0, "max_cost_usd": 0.01, "deny_arms": [], "w_quality": 1.0, "w_cost": 0.1, "w_latency": 0.1}}, "metrics": {"cpu_ms_small": 1.1652519997369382, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 3, "smoke_pass": 1, "framework_langchain": 1, "framework_autogen": 0}, "explanation": "Chose basic_agentic given context; tuned steps to 3. Quality=0.10, Cost=$0.0000, Latency=0.00s."}
{"t": 23, "arm": "reflective_agentic", "reward": 0.1, "quality": 0.1, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.999, "plan": {"framework": "AutoGen", "tools": ["python_repl", "search", "retry", "reflect"], "max_steps": 5, "task": "summarize", "task_input": "Reflective agents can retry and self-evaluate; graphs orchestrate multi-step reasoning.", "constraints": {"max_latency_s": 2.0, "max_cost_usd": 0.01, "deny_arms": [], "w_quality": 1.0, "w_cost": 0.1, "w_latency": 0.1}}, "metrics": {"cpu_ms_small": 0.6723189999320311, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 1}, "explanation": "Chose reflective_agentic given context; tuned steps to 5. Quality=0.10, Cost=$0.0000, Latency=0.00s."}
{"t": 24, "arm": "graph_agentic", "reward": 0.1, "quality": 0.1, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.999, "plan": {"framework": "GraphPlanner", "tools": ["router", "python_repl", "reflect", "retry", "search"], "max_steps": 5, "task": "summarize", "task_input": "BAAS selects among agent patterns to optimize quality, cost, and latency.", "constraints": {"max_latency_s": 2.0, "max_cost_usd": 0.01, "deny_arms": [], "w_quality": 1.0, "w_cost": 0.1, "w_latency": 0.1}}, "metrics": {"cpu_ms_small": 0.4598120003720396, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 0}, "explanation": "Chose graph_agentic given context; tuned steps to 5. Quality=0.10, Cost=$0.0000, Latency=0.00s."}
{"t": 25, "arm": "llm_agentic", "reward": 0.0, "quality": 5.594217588506538e-21, "usd_cost": 0.000334, "latency_s": 0.0, "tuned_p": 0.999, "plan": {"framework": "LiteAgent", "tools": ["python_repl", "search", "retry"], "max_steps": 5, "_llm_metrics": {"llm_ok": 1, "llm_latency_s": 0.885533332824707, "llm_out_len": 80, "llm_text": "{\"framework\":\"LiteAgent\",\"tools\":[\"python_repl\",\"search\",\"retry\"],\"max_steps\":6}", "usd_cost": 0.000334}, "task": "summarize", "task_input": "BAAS selects among agent patterns to optimize quality, cost, and latency.", "constraints": {"max_latency_s": 2.0, "max_cost_usd": 0.01, "deny_arms": [], "w_quality": 1.0, "w_cost": 0.1, "w_latency": 0.1}}, "metrics": {"cpu_ms_small": 0.48980300016410183, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 0, "llm_ok": 1, "llm_latency_s": 0.885533332824707, "llm_out_len": 80, "llm_text": "{\"framework\":\"LiteAgent\",\"tools\":[\"python_repl\",\"search\",\"retry\"],\"max_steps\":6}", "usd_cost": 0.000334}, "explanation": "Chose llm_agentic given context; tuned steps to 5. Quality=0.00, Cost=$0.0003, Latency=0.00s."}
{"t": 26, "arm": "basic_agentic", "reward": 0.1, "quality": 0.1, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.001, "plan": {"framework": "LangChain", "tools": ["python_repl", "search"], "max_steps": 3, "task": "summarize", "task_input": "BAAS selects among agent patterns to optimize quality, cost, and latency.", "constraints": {"max_latency_s": 2.0, "max_cost_usd": 0.01, "deny_arms": [], "w_quality": 1.0, "w_cost": 0.1, "w_latency": 0.1}}, "metrics": {"cpu_ms_small": 0.5878749998373678, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 3, "smoke_pass": 1, "framework_langchain": 1, "framework_autogen": 0}, "explanation": "Chose basic_agentic given context; tuned steps to 3. Quality=0.10, Cost=$0.0000, Latency=0.00s."}
{"t": 27, "arm": "reflective_agentic", "reward": 0.1, "quality": 0.1, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.999, "plan": {"framework": "AutoGen", "tools": ["python_repl", "search", "retry", "reflect"], "max_steps": 5, "task": "summarize", "task_input": "BAAS selects among agent patterns to optimize quality, cost, and latency.", "constraints": {"max_latency_s": 2.0, "max_cost_usd": 0.01, "deny_arms": [], "w_quality": 1.0, "w_cost": 0.1, "w_latency": 0.1}}, "metrics": {"cpu_ms_small": 0.5771409996668808, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 1}, "explanation": "Chose reflective_agentic given context; tuned steps to 5. Quality=0.10, Cost=$0.0000, Latency=0.00s."}
{"t": 28, "arm": "graph_agentic", "reward": 0.1, "quality": 0.1, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.999, "plan": {"framework": "GraphPlanner", "tools": ["router", "python_repl", "reflect", "retry", "search"], "max_steps": 5, "task": "summarize", "task_input": "Reflective agents can retry and self-evaluate; graphs orchestrate multi-step reasoning.", "constraints": {"max_latency_s": 2.0, "max_cost_usd": 0.01, "deny_arms": [], "w_quality": 1.0, "w_cost": 0.1, "w_latency": 0.1}}, "metrics": {"cpu_ms_small": 0.583206000555947, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 5, "smoke_pass": 1, "framework_langchain": 0, "framework_autogen": 0}, "explanation": "Chose graph_agentic given context; tuned steps to 5. Quality=0.10, Cost=$0.0000, Latency=0.00s."}
{"t": 29, "arm": "basic_agentic", "reward": 0.1, "quality": 0.1, "usd_cost": 0.0, "latency_s": 0.0, "tuned_p": 0.001, "plan": {"framework": "LangChain", "tools": ["python_repl", "search"], "max_steps": 3, "task": "summarize", "task_input": "Reflective agents can retry and self-evaluate; graphs orchestrate multi-step reasoning.", "constraints": {"max_latency_s": 2.0, "max_cost_usd": 0.01, "deny_arms": [], "w_quality": 1.0, "w_cost": 0.1, "w_latency": 0.1}}, "metrics": {"cpu_ms_small": 0.6352880000122241, "compute_ok": 1, "has_torch": 0, "has_transformers": 1, "steps_budget": 3, "smoke_pass": 1, "framework_langchain": 1, "framework_autogen": 0}, "explanation": "Chose basic_agentic given context; tuned steps to 3. Quality=0.10, Cost=$0.0000, Latency=0.00s."}
